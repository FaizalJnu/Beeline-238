
This tutorial will first explain the structure of the Beeline repository,
with a walkthrough of the different components that the user can customize.


Project outline
###############

The BEELINE repository is structured as follows:

.. code:: text

          Beeline
          |-- inputs/
          |   `-- examples/
          |       `-- GSD/
          |           |--refNetwork.csv
          |           |--PseudoTime.csv
          |           `--ExpressionData.csv
          |-- config-files/
          |   `-- config.yaml
          |-- BLRun/
          |   |-- sinceritiesRunner.py
          |   `-- ...
          |-- BLPlot/
          |   |-- NetworkMotifs.py  
          |   `-- CuratedOverview.py
          |-- BLEval/
          |   |-- parseTime.py
          |    `-- ...
          `-- Algorithms/
              `-- SINCERITIES/

Input files
###########

The sample input data set provided is generated by :ref:`BoolODE`
using the Boolean model of `Gonadal Sex Determination
<https://www.ncbi.nlm.nih.gov/pubmed/26573569>`_ as input.  Note that
this dataset has been pre-processed to produce three files that are
required in the BEELINE pipline. 

1. `ExpressionData.csv` contains the RNAseq data, with genes as
   rows and cell IDs as columns. This file is a required input to the
   pipline
2. `PseudoTime.csv` contains the pseudotime values for the cells in
   `ExpressionData.csv`.  We recommend using the Slingshot method to
   obtain the pseudotime for a dataset. Many algorithms in the
   pipeline require a pseudotime file as input.
3. `refNetwork.csv` contains the ground truth network underlying the
   interactions between genes in `ExpressionData.csv`. Typically this
   network is not available, and will have to be curated from various
   Transcription Factor databases. While this file is not a
   requirement to run the base pipeline, a reference network is
   required to run some of the performance evaluations in
   :ref:`BLEval`.


The figure below shows the t-SNE visualization of the expression
data from the example dataset. 

.. image:: figs/SlingshotOutputVis.png

This dataset shows a bifurcating
trajectory, as is evidenced by the part (a) of the figure, where
each 'cell' is colored by the timepoint at which it was sampled
in the simulation (the darker colors indicate earlier time points).
Clustering the simulation confirms the two trajectories, indicated
in red and blue respectively in part (b). Finally, running Slingshot
on this dataset and specifying the cluster of cells corresponding to
the early time points yields two pseudotime trajectories, shown in part (c).
           

.. attention:: Please ensure that any input dataset you create is
               comma separated, and contains the correct style of
               column names.


Config files
############

Beeline uses `YAML <https://yaml.org/>`_ files to allow users to
flexibly specify inputs and algorithm run parameters. A sample config file is
provided in `config-files/`. A config file should contain at minimum

.. code:: text

          input_settings:
              datasets:
                  - name: "Dataset name"
                    exprData: "Expression Data filename"
                    cellData: "PseudoTime filename"
                    trueEdges: "Ground truth network filename"

              algorithms:
                  - name: "Algorithm name"
                    params:
                        # Any other parameters that can be passed to
                        # this algorithm
                        should_run: [True] # or False
               

Apart from indicating the path to the base directory and the specific
folder containing the input, the config file indicates which
algorithms should be run, along with the parameters to be passed to
the algorithms, if any. For a list of parameters that the pipeline
currently passes to the algorithms, see  :ref:`algorithms`  .  Finally,
the YAML file also specifies the paths to the outputs.

.. attention:: Please ensure that the YAML file is correctly indented!

Running the pipeline
####################

``BLRun.py`` requires the path to the config file to be specified.

Command line arguments:
  -h, --help            show this help message and exit
  --config              Path to the config file
        

Once the input dataset has been generated and the config file has been
created, the pipeline can be executed by simply calling ``BLRun.py``
with the config file specifying the inputs and the algorithms to run,
passed using the ``--config`` option which takes the path to the
config file.

The ``BLRun.py`` creates a :obj:`BLRun` object for each algorithm
specified in the config file. Each :obj:`BLRun` object should contain three
modules

1. ``generateInputs()`` : This function reads the three input data
   files, and processes them into the format required by the given
   algorithm
2. ``run()`` : A function to construct a system command with the
   appropriate command line parameters to be passed to the docker
   container in order to run a given algorithm
3. ``parseOutput()`` : A function to read the algorithm-specific
   output and reformat it into a standard format

The evaluation scripts in the final step of the pipeline expect the
inferred networks from each algorithm to be a comma-separated file
with the following format:

.. code:: text

          Gene1,Gene2,EdgeWeight
          reg1,targ1,edgeweight

where the first line are the column names, and the subsequent lines
contain the edges predicted by the network. The Gene1 column should
contain regulators, the Gene2 column the targets, and EdgeWeight
column the absolute value of the weight predicted for edge (regulator,
target).

Running the evaluation scripts
##############################

``BLEval.py`` requires the path to the config file. Optionally the list
of evaluations to be performed can be specified. The available options are
list below.
    
Command line arguments:
  -h, --help            show this help message and exit
  -c CONFIG, --config CONFIG
                        Configuration file containing list of datasets
                        algorithms and output specifications.
  -a, --auc             Compute median of areas under Precision-Recall and ROC
                        curves. Calls :mod:`BLEval.computeAUC`.
  -j, --jaccard         Compute median Jaccard index of predicted top-k
                        networks for each algorithm for a given set of
                        datasets generated from the same ground truth network. Calls :mod:`BLEval.computeJaccard`.
  -r, --spearman        Compute median Spearman Corr. of predicted edges for
                        each algorithm for a given set of datasets generated
                        from the same ground truth network.  Calls :mod:`BLEval.computeSpearman`.
  -t, --time            Analyze time taken by each algorithm for a. Calls :mod:`BLEval.parseTime`.
  -e, --epr             Compute median early precision. Calls :mod:`BLEval.computeEarlyPrec`.
  -s, --sepr            Analyze median (signed) early precision for activation
                        and inhibitory edges. :mod:`BLEval.computeSignedEPrec`.
  -m, --motifs          Compute network motifs in the predicted top-k
                        networks. Calls :mod:`BLEval.computeNetMotifs`.


The evaluation of the inferred networks is done by calling the
``BLEvalAggregator.py`` script.  Like the ``BLRun.py`` script, the
EvalAggregator script takes the config file as input. Every  subsequent
option passed to this script calls a different evaluation script.

